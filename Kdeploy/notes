
What is really a constant? We know constants are excluded from the actual function call.
Ex: 
def add_kernel(x_ptr,  # *Pointer* to first input vector.
               y_ptr,  # *Pointer* to second input vector.
               output_ptr,  # *Pointer* to output vector.
               n_elements,  # Size of the vector.
               BLOCK_SIZE: tl.constexpr):
The C function call does not include the BLOCK_SIZE parameter as its a compile-time constant. 

However, consider: 

@triton.jit
def matmul_kernel(
        # Pointers to matrices
        a_ptr, b_ptr, c_ptr,
        # Matrix dimensions
        M, N, K,
        # The stride variables represent how much to increase the ptr by when moving by 1
        # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`
        # by to get the element one row down (A has M rows).
        stride_am, stride_ak,  #
        stride_bk, stride_bn,  #
        stride_cm, stride_cn,
        # Meta-parameters
        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #
        GROUP_SIZE_M: tl.constexpr,  #
        USE_BLOCK_POINTERS: tl.constexpr,  #
):

BLOCK_SIZE_M, BLOCK_SIZE_N, ... USE_BLOCK_POINTERS are clear constants (tl.constexpr)
However, apparently stride_ak, stride_bn, stride_cn (but not am, bk, cm) are classified as constants too. Why? 
Note: in this case, these strides happen to be 1, while the other strides are some other value

triton/runtime/jit.py:
	configs = (backend.get_attrs_descriptor(self.params, bound_vals), )
	constant_params = configs[0].get_constants() # this shows the stride parameters (ak, bn, cn)
	constants = {
		p.name: v
		for (v, p) in zip(bound_vals, self.params)
		if p.is_constexpr or (p.num in constant_params) or v is None
	}

	print(configs[0]) # AttrsDescriptor.from_dict({'arg_properties': {'tt.divisibility': [0, 1, 2], 'tt.equal_to': [7, 9, 11]}, 'cls': 'AttrsDescriptor'})
	print(configs[0].constant_properties) # {'tt.equal_to'}

7, 9, 11 are the indices for the stride params that are being treated as constant

triton/backends/compiler.py:
	self.arg_properties["tt.equal_to"] = [
		param.num
		for param, arg in zip(params, values)
		if AttrsDescriptor.is_equal_to_1(arg) and not param.do_not_specialize
	]
Performs a specialized compilation of the function when certain args = 1

Possible fix: tell the decorator to not specialize any non-constant parameters
@triton.jit(do_not_specialize=list(range(12))) # indices of parameters that arent constant
def matmul_kernel(...)
See decorator definition in triton/runtime/jit.py: def jit(...)

-fstack-usage gets max stack size
https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html
or just vmalloc a regular user-sized stack (8MiB in Linux according to google) downsides?


create github repo, slide deck

to dump asm: 
TRITON_CPU_BACKEND=1 TRITON_KERNEL_DUMP=1 TRITON_ALWAYS_COMPILE=1 TRITON_DUMP_DIR=. python3 test.py

launching a kernel syntax:
kernel[grid](...)

breaking down launching a kernel: 
runtime/jit.py: KernelInterface.__getitem__() calls self.run()
runtime/jit.py: self.run()
		compiles kernel if not compiled already
		kernel.launch_metadata
		kernel.run(grid dimensions, stream?, kernel.packed_metadata, launch_metadata, CompiledKernel.launch_enter_hook, CompiledKernel.launch_exit_hook, non constexpr values)
compiler/compiler.py: self.run = driver.active.launcher_cls(self.src, self.metadata)
triton/backends/cpu/driver.py: run_omp_kernels(...) calls kernel_ptr(..., x, y, z, gridX, gridY, gridZ)



OPENMP STUFF (N/A) example grid: (idk what a grid is) 
grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), )
meta is a dict of the params that you are passing to the kernel

arg: tl.constexpr means that it will not be a real argument to the kernel!
ex: add_vectors(int* a, int* b, int* out, int arr_size, constexpr int BLOCK_SIZE)
kernel definition: add_vectors(int* a, int* b, int* out, int arr_size, int x, int y, int z, int gridX, int gridY, int gridZ)

x, y, z is a particular execution from the larger grid

run_omp_kernels will run the kernels using OpenMP


